{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"https://gitlab.com/ibm/skills-network/courses/placeholder101/-/raw/master/labs/module%201/images/IDSNlogo.png\"  width=\"300\" alt=\"cognitiveclass.ai logo\"  />\n",
    "</center>\n",
    "\n",
    "<h1 align=center><font size = 5>Assignment: SQL Notebook for Peer Assignment</font></h1>\n",
    "\n",
    "Estimated time needed: **60** minutes.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Using this Python notebook you will:\n",
    "\n",
    "1.  Understand the Spacex DataSet\n",
    "2.  Load the dataset  into the corresponding table in a Db2 database\n",
    "3.  Execute SQL queries to answer assignment questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of the DataSet\n",
    "\n",
    "SpaceX has gained worldwide attention for a series of historic milestones.\n",
    "\n",
    "It is the only private company ever to return a spacecraft from low-earth orbit, which it first accomplished in December 2010.\n",
    "SpaceX advertises Falcon 9 rocket launches on its website with a cost of 62 million dollars wheras other providers cost upward of 165 million dollars each, much of the savings is because Space X can reuse the first stage.\n",
    "\n",
    "Therefore if we can determine if the first stage will land, we can determine the cost of a launch.\n",
    "\n",
    "This information can be used if an alternate company wants to bid against SpaceX for a rocket launch.\n",
    "\n",
    "This dataset includes a record for each payload carried during a SpaceX mission into outer space.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the datasets\n",
    "\n",
    "This assignment requires you to load the spacex dataset.\n",
    "\n",
    "In many cases the dataset to be analyzed is available as a .CSV (comma separated values) file, perhaps on the internet. Click on the link below to download and save the dataset (.CSV file):\n",
    "\n",
    "<a href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_2/data/Spacex.csv?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDS0321ENSkillsNetwork26802033-2021-01-01\" target=\"_blank\">Spacex DataSet</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the dataset in database table\n",
    "\n",
    "**it is highly recommended to manually load the table using the database console LOAD tool in DB2**.\n",
    "\n",
    "<img src = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_2/images/spacexload.png\">\n",
    "\n",
    "Now open the Db2 console, open the LOAD tool, Select / Drag the .CSV file for the  dataset, Next create a New Table, and then follow the steps on-screen instructions to load the data. Name the new table as follows:\n",
    "\n",
    "**SPACEXDATASET**\n",
    "\n",
    "**Follow these steps while using old DB2 UI which is having Open Console Screen**\n",
    "\n",
    "**Note:While loading Spacex dataset, ensure that detect datatypes is disabled. Later click on the pencil icon(edit option).**\n",
    "\n",
    "1.  Change the Date Format by manually typing DD-MM-YYYY and timestamp format as DD-MM-YYYY HH\\:MM:SS.\n",
    "\n",
    "    Here you should place the cursor at Date field and manually type as DD-MM-YYYY.\n",
    "\n",
    "2.  Change the PAYLOAD_MASS\\_\\_KG\\_  datatype  to INTEGER.\n",
    "\n",
    "<img src = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_2/images/spacexload2.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Changes to be considered when having DB2 instance with the new UI having Go to UI screen**\n",
    "\n",
    "*   Refer to this insruction in this <a href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DB0201EN-SkillsNetwork/labs/Labs_Coursera_V5/labs/Lab%20-%20Sign%20up%20for%20IBM%20Cloud%20-%20Create%20Db2%20service%20instance%20-%20Get%20started%20with%20the%20Db2%20console/instructional-labs.md.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDS0321ENSkillsNetwork26802033-2021-01-01\">link</a> for viewing  the new  Go to UI screen.\n",
    "\n",
    "*   Later click on **Data link(below SQL)**  in the Go to UI screen  and click on **Load Data** tab.\n",
    "\n",
    "*   Later browse for the downloaded spacex file.\n",
    "\n",
    "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_2/images/browsefile.png\" width=\"800\"/>\n",
    "\n",
    "*   Once done select the schema andload the file.\n",
    "\n",
    " <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_2/images/spacexload3.png\" width=\"800\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, it was difficult to access IBM's Db2 due to high demand. To complete this exercise, we would make use of the postgre SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T20:01:31.087901Z",
     "start_time": "2024-02-19T20:01:28.127064700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2 in c:\\users\\megan\\downloads\\venv\\lib\\site-packages (2.9.9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project libraries has been successfully installed!\n"
     ]
    }
   ],
   "source": [
    "# install for connection to postgres database (local)\n",
    "!pip install psycopg2\n",
    "\n",
    "import csv\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "\n",
    "# install for connection to the database using DB2 (cloud)\n",
    "#!pip install sqlalchemy==1.3.9\n",
    "#!pip install ibm_db_sa\n",
    "#!pip install ipython-sql\n",
    "print('Project libraries has been successfully installed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the database using DB2\n",
    "\n",
    "Let us first load the SQL extension and establish a connection with the database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T20:01:31.339072700Z",
     "start_time": "2024-02-19T20:01:31.087901Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DB2 magic in case of old UI service credentials.**\n",
    "\n",
    "In the next cell enter your db2 connection string. Recall you created Service Credentials for your Db2 instance before. From the **uri** field of your Db2 service credentials copy everything after db2:// (except the double quote at the end) and paste it in the cell below after ibm_db_sa://\n",
    "\n",
    "<img src =\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DB0201EN-SkillsNetwork/labs/FinalModule_edX/images/URI.jpg\">\n",
    "\n",
    "in the following format\n",
    "\n",
    "**%sql ibm_db_sa://my-username:my-password\\@my-hostname:my-port/my-db-name**\n",
    "\n",
    "**DB2 magic in case of new UI service credentials.**\n",
    "\n",
    "<img src =\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_2/images/servicecredentials.png\" width=600>  \n",
    "\n",
    "*   Use the following format.\n",
    "\n",
    "*   Add security=SSL at the end\n",
    "\n",
    "**%sql ibm_db_sa://my-username:my-password\\@my-hostname:my-port/my-db-name?security=SSL**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T20:01:31.417818500Z",
     "start_time": "2024-02-19T20:01:31.339072700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Megan\\Downloads\\venv\\lib\\site-packages\\sql\\connection.py\", line 45, in __init__\n",
      "    engine = sqlalchemy.create_engine(\n",
      "  File \"<string>\", line 2, in create_engine\n",
      "  File \"C:\\Users\\Megan\\Downloads\\venv\\lib\\site-packages\\sqlalchemy\\util\\deprecations.py\", line 281, in warned\n",
      "    return fn(*args, **kwargs)  # type: ignore[no-any-return]\n",
      "  File \"C:\\Users\\Megan\\Downloads\\venv\\lib\\site-packages\\sqlalchemy\\engine\\create.py\", line 599, in create_engine\n",
      "    dbapi = dbapi_meth(**dbapi_args)\n",
      "  File \"C:\\Users\\Megan\\Downloads\\venv\\lib\\site-packages\\ibm_db_sa\\ibm_db.py\", line 130, in import_dbapi\n",
      "    import ibm_db_dbi as module\n",
      "  File \"C:\\Users\\Megan\\Downloads\\venv\\lib\\site-packages\\ibm_db_dbi.py\", line 45, in <module>\n",
      "    import ibm_db\n",
      "ImportError: DLL load failed while importing ibm_db: The specified module could not be found.\n",
      "\n",
      "Connection info needed in SQLAlchemy format, example:\n",
      "               postgresql://username:password@hostname/dbname\n",
      "               or an existing connection: dict_keys([])\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Megan\\Downloads\\venv\\lib\\site-packages\\sql\\magic.py\", line 196, in execute\n",
      "    conn = sql.connection.Connection.set(\n",
      "  File \"C:\\Users\\Megan\\Downloads\\venv\\lib\\site-packages\\sql\\connection.py\", line 70, in set\n",
      "    cls.current = existing or Connection(descriptor, connect_args, creator)\n",
      "  File \"C:\\Users\\Megan\\Downloads\\venv\\lib\\site-packages\\sql\\connection.py\", line 45, in __init__\n",
      "    engine = sqlalchemy.create_engine(\n",
      "  File \"<string>\", line 2, in create_engine\n",
      "  File \"C:\\Users\\Megan\\Downloads\\venv\\lib\\site-packages\\sqlalchemy\\util\\deprecations.py\", line 281, in warned\n",
      "    return fn(*args, **kwargs)  # type: ignore[no-any-return]\n",
      "  File \"C:\\Users\\Megan\\Downloads\\venv\\lib\\site-packages\\sqlalchemy\\engine\\create.py\", line 599, in create_engine\n",
      "    dbapi = dbapi_meth(**dbapi_args)\n",
      "  File \"C:\\Users\\Megan\\Downloads\\venv\\lib\\site-packages\\ibm_db_sa\\ibm_db.py\", line 130, in import_dbapi\n",
      "    import ibm_db_dbi as module\n",
      "  File \"C:\\Users\\Megan\\Downloads\\venv\\lib\\site-packages\\ibm_db_dbi.py\", line 45, in <module>\n",
      "    import ibm_db\n",
      "ImportError: DLL load failed while importing ibm_db: The specified module could not be found.\n",
      "\n",
      "Connection info needed in SQLAlchemy format, example:\n",
      "               postgresql://username:password@hostname/dbname\n",
      "               or an existing connection: dict_keys([])\n"
     ]
    }
   ],
   "source": [
    "%sql ibm_db_sa://"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T20:01:31.465176200Z",
     "start_time": "2024-02-19T20:01:31.417818500Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the database using PostgreSQL database\n",
    "\n",
    "We tried to establish connection to the cloud database but experienced some difficulty so we decided to use the postgreSQL database. Let us load the SQL extension and establish a connection with the database using the jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T20:02:02.841294500Z",
     "start_time": "2024-02-19T20:01:58.694612700Z"
    }
   },
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "connection to server at \"localhost\" (::1), port 5432 failed: Connection refused (0x0000274D/10061)\n\tIs the server running on that host and accepting TCP/IP connections?\nconnection to server at \"localhost\" (127.0.0.1), port 5432 failed: Connection refused (0x0000274D/10061)\n\tIs the server running on that host and accepting TCP/IP connections?\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOperationalError\u001B[0m                          Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# create connection to postgreSQL database\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m conn \u001B[38;5;241m=\u001B[39m \u001B[43mpsycopg2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnect\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhost\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlocalhost\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdatabase\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpostgres\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43muser\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpostgres\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpassword\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mchuksoo\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mport\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m5432\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mConnection to database is successfully\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\Downloads\\venv\\lib\\site-packages\\psycopg2\\__init__.py:122\u001B[0m, in \u001B[0;36mconnect\u001B[1;34m(dsn, connection_factory, cursor_factory, **kwargs)\u001B[0m\n\u001B[0;32m    119\u001B[0m     kwasync[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124masync_\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124masync_\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    121\u001B[0m dsn \u001B[38;5;241m=\u001B[39m _ext\u001B[38;5;241m.\u001B[39mmake_dsn(dsn, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m--> 122\u001B[0m conn \u001B[38;5;241m=\u001B[39m _connect(dsn, connection_factory\u001B[38;5;241m=\u001B[39mconnection_factory, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwasync)\n\u001B[0;32m    123\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cursor_factory \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    124\u001B[0m     conn\u001B[38;5;241m.\u001B[39mcursor_factory \u001B[38;5;241m=\u001B[39m cursor_factory\n",
      "\u001B[1;31mOperationalError\u001B[0m: connection to server at \"localhost\" (::1), port 5432 failed: Connection refused (0x0000274D/10061)\n\tIs the server running on that host and accepting TCP/IP connections?\nconnection to server at \"localhost\" (127.0.0.1), port 5432 failed: Connection refused (0x0000274D/10061)\n\tIs the server running on that host and accepting TCP/IP connections?\n"
     ]
    }
   ],
   "source": [
    "# create connection to postgreSQL database\n",
    "conn = psycopg2.connect(\n",
    "    host = 'localhost',\n",
    "    database = 'postgres', \n",
    "    user = 'postgres', \n",
    "    password = 'chuksoo',  \n",
    "    port = '5432')\n",
    "print('Connection to database is successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T20:01:54.067245Z",
     "start_time": "2024-02-19T20:01:54.005305500Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'conn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 48\u001B[0m\n\u001B[0;32m     45\u001B[0m     conn\u001B[38;5;241m.\u001B[39mclose()   \n\u001B[0;32m     47\u001B[0m \u001B[38;5;66;03m# function to create pandas dataframe\u001B[39;00m\n\u001B[1;32m---> 48\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate_pandas_df\u001B[39m(sql_query, database\u001B[38;5;241m=\u001B[39m\u001B[43mconn\u001B[49m):\n\u001B[0;32m     49\u001B[0m     table \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_sql_query(sql_query, database)\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m table\n",
      "\u001B[1;31mNameError\u001B[0m: name 'conn' is not defined"
     ]
    }
   ],
   "source": [
    "# function to read from database\n",
    "def read(conn, read_):\n",
    "    print('Read')\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(read_)\n",
    "    for row in cursor:\n",
    "        print(f'row = {row}')\n",
    "    print()\n",
    "    \n",
    "# function to create in postgre database     \n",
    "def create(conn, create_):\n",
    "    cursor = conn.cursor() # create cursor object\n",
    "    cursor.execute(create_) # execute query\n",
    "    conn.commit() # commit query to database\n",
    "    print('Table have been created successfull!!!')\n",
    "    #read(conn)\n",
    "    \n",
    "# function to insert in postgre database     \n",
    "def insert(conn, insert_):\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(insert_)\n",
    "    conn.commit()\n",
    "    print('Records have been successfully inserted!!!')\n",
    "    #read(conn)\n",
    "    \n",
    "# function to update table\n",
    "def update(conn, update_):\n",
    "    print('Update')\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(update_)\n",
    "    conn.commit()\n",
    "    #read(conn)\n",
    "    \n",
    "# function to delete in postgre database\n",
    "def delete(conn, delete_):\n",
    "    print('Delete')\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(delete_)\n",
    "    conn.commit()\n",
    "    #read(conn)\n",
    "\n",
    "# close the cursor and connection to the server \n",
    "def close():\n",
    "    cursor.close()\n",
    "    conn.close()   \n",
    "    \n",
    "# function to create pandas dataframe\n",
    "def create_pandas_df(sql_query, database=conn):\n",
    "    table = pd.read_sql_query(sql_query, database)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, we have to create the table in the database using the `CREATE` function. Next we insert the **csv** file by loading the `csv` module. Then we would run the `INSERT` query for each row and then commit the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create table in postgreSQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T20:01:50.197346500Z",
     "start_time": "2024-02-19T20:01:50.150520Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 18\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# create table SpaceX\u001B[39;00m\n\u001B[0;32m      2\u001B[0m create_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'''\u001B[39m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;124m            DROP TABLE IF EXISTS SpaceX;\u001B[39m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;124m            CREATE TABLE SpaceX\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;124m                );\u001B[39m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;124m            \u001B[39m\u001B[38;5;124m'''\u001B[39m\n\u001B[1;32m---> 18\u001B[0m \u001B[43mcreate\u001B[49m(conn, create_)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'create' is not defined"
     ]
    }
   ],
   "source": [
    "# create table SpaceX\n",
    "create_ = '''\n",
    "            DROP TABLE IF EXISTS SpaceX;\n",
    "            CREATE TABLE SpaceX\n",
    "                (\n",
    "                    Date DATE NULL,\n",
    "                    Time TIME NULL,\n",
    "                    BoosterVersion VARCHAR(50) NULL,\n",
    "                    LaunchSite VARCHAR(50) NULL,\n",
    "                    Payload VARCHAR(100) NULL,\n",
    "                    PayloadMassKG INT NULL,\n",
    "                    Orbit VARCHAR(50) NULL,\n",
    "                    Customer VARCHAR(100) NULL,\n",
    "                    MissionOutcome VARCHAR(50) NULL,\n",
    "                    LandingOutcome VARCHAR(100) NULL\n",
    "                );\n",
    "            '''\n",
    "create(conn, create_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we already have the postgreSQL database open, we would have seen that the table have been created by now. Next we load the csv file using the csv module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the csv file\n",
    "cursor = conn.cursor()\n",
    "with open('Spacex.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader) # Skip the header row.\n",
    "    for row in reader:\n",
    "        cursor.execute(\n",
    "        \"INSERT INTO SpaceX VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\",\n",
    "        row\n",
    "    )\n",
    "conn.commit()\n",
    "print('CSV file inserted into database successfully!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read to see that data has been uploaded in database\n",
    "read_ = '''\n",
    "        SELECT *\n",
    "        FROM   SpaceX\n",
    "        LIMIT 10\n",
    "        '''\n",
    "read(conn, read_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output postgre query in pandas dataframe\n",
    "spacex = create_pandas_df(read_, database=conn)\n",
    "spacex.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "\n",
    "Now write and execute SQL queries to solve the assignment tasks.\n",
    "\n",
    "### Task 1\n",
    "\n",
    "##### Display the names of the unique launch sites  in the space mission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_1 = '''\n",
    "        SELECT DISTINCT LaunchSite \n",
    "        FROM SpaceX\n",
    "'''\n",
    "create_pandas_df(task_1, database=conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "\n",
    "##### Display 5 records where launch sites begin with the string 'CCA'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_2 = '''\n",
    "        SELECT *\n",
    "        FROM SpaceX\n",
    "        WHERE LaunchSite LIKE 'CCA%'\n",
    "        LIMIT 5\n",
    "        '''\n",
    "create_pandas_df(task_2, database=conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "\n",
    "##### Display the total payload mass carried by boosters launched by NASA (CRS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_3 = '''\n",
    "        SELECT SUM(PayloadMassKG) AS Total_PayloadMass\n",
    "        FROM SpaceX\n",
    "        WHERE Customer LIKE 'NASA (CRS)'\n",
    "        '''\n",
    "create_pandas_df(task_3, database=conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4\n",
    "\n",
    "##### Display average payload mass carried by booster version F9 v1.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_4 = '''\n",
    "        SELECT AVG(PayloadMassKG) AS Avg_PayloadMass\n",
    "        FROM SpaceX\n",
    "        WHERE BoosterVersion = 'F9 v1.1'\n",
    "        '''\n",
    "create_pandas_df(task_4, database=conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5\n",
    "\n",
    "##### List the date when the first successful landing outcome in ground pad was acheived.\n",
    "\n",
    "*Hint:Use min function*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_5 = '''\n",
    "        SELECT MIN(Date) AS FirstSuccessfull_landing_date\n",
    "        FROM SpaceX\n",
    "        WHERE LandingOutcome LIKE 'Success (ground pad)'\n",
    "        '''\n",
    "create_pandas_df(task_5, database=conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6\n",
    "\n",
    "##### List the names of the boosters which have success in drone ship and have payload mass greater than 4000 but less than 6000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_6 = '''\n",
    "        SELECT BoosterVersion\n",
    "        FROM SpaceX\n",
    "        WHERE LandingOutcome = 'Success (drone ship)'\n",
    "            AND PayloadMassKG > 4000 \n",
    "            AND PayloadMassKG < 6000\n",
    "        '''\n",
    "create_pandas_df(task_6, database=conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7\n",
    "\n",
    "##### List the total number of successful and failure mission outcomes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_7a = '''\n",
    "        SELECT COUNT(MissionOutcome) AS SuccessOutcome\n",
    "        FROM SpaceX\n",
    "        WHERE MissionOutcome LIKE 'Success%'\n",
    "        '''\n",
    "\n",
    "task_7b = '''\n",
    "        SELECT COUNT(MissionOutcome) AS FailureOutcome\n",
    "        FROM SpaceX\n",
    "        WHERE MissionOutcome LIKE 'Failure%'\n",
    "        '''\n",
    "print('The total number of successful mission outcome is:')\n",
    "display(create_pandas_df(task_7a, database=conn))\n",
    "print()\n",
    "print('The total number of failed mission outcome is:')\n",
    "create_pandas_df(task_7b, database=conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8\n",
    "\n",
    "##### List the   names of the booster_versions which have carried the maximum payload mass. Use a subquery\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_8 = '''\n",
    "        SELECT BoosterVersion, PayloadMassKG\n",
    "        FROM SpaceX\n",
    "        WHERE PayloadMassKG = (\n",
    "                                SELECT MAX(PayloadMassKG)\n",
    "                                FROM SpaceX\n",
    "                                )\n",
    "        ORDER BY BoosterVersion\n",
    "        '''\n",
    "create_pandas_df(task_8, database=conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 9\n",
    "\n",
    "##### List the failed landing_outcomes in drone ship, their booster versions, and launch site names for in year 2015\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_9 = '''\n",
    "        SELECT BoosterVersion, LaunchSite, LandingOutcome\n",
    "        FROM SpaceX\n",
    "        WHERE LandingOutcome LIKE 'Failure (drone ship)'\n",
    "            AND Date BETWEEN '2015-01-01' AND '2015-12-31'\n",
    "        '''\n",
    "create_pandas_df(task_9, database=conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 10\n",
    "\n",
    "##### Rank the count of landing outcomes (such as Failure (drone ship) or Success (ground pad)) between the date 2010-06-04 and 2017-03-20, in descending order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_10 = '''\n",
    "        SELECT LandingOutcome, COUNT(LandingOutcome)\n",
    "        FROM SpaceX\n",
    "        WHERE DATE BETWEEN '2010-06-04' AND '2017-03-20'\n",
    "        GROUP BY LandingOutcome\n",
    "        ORDER BY COUNT(LandingOutcome) DESC\n",
    "        '''\n",
    "create_pandas_df(task_10, database=conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference Links\n",
    "\n",
    "*   <a href =\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DB0201EN-SkillsNetwork/labs/Labs_Coursera_V5/labs/Lab%20-%20String%20Patterns%20-%20Sorting%20-%20Grouping/instructional-labs.md.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDS0321ENSkillsNetwork26802033-2021-01-01&origin=www.coursera.org\">Hands-on Lab : String Patterns, Sorting and Grouping</a>\n",
    "\n",
    "*   <a  href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DB0201EN-SkillsNetwork/labs/Labs_Coursera_V5/labs/Lab%20-%20Built-in%20functions%20/Hands-on_Lab__Built-in_Functions.md.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDS0321ENSkillsNetwork26802033-2021-01-01&origin=www.coursera.org\">Hands-on Lab: Built-in functions</a>\n",
    "\n",
    "*   <a  href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DB0201EN-SkillsNetwork/labs/Labs_Coursera_V5/labs/Lab%20-%20Sub-queries%20and%20Nested%20SELECTs%20/instructional-labs.md.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDS0321ENSkillsNetwork26802033-2021-01-01&origin=www.coursera.org\">Hands-on Lab : Sub-queries and Nested SELECT Statements</a>\n",
    "\n",
    "*   <a href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DB0201EN-SkillsNetwork/labs/Module%205/DB0201EN-Week3-1-3-SQLmagic.ipynb?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDS0321ENSkillsNetwork26802033-2021-01-01\">Hands-on Tutorial: Accessing Databases with SQL magic</a>\n",
    "\n",
    "*   <a href= \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DB0201EN-SkillsNetwork/labs/Module%205/DB0201EN-Week3-1-4-Analyzing.ipynb?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDS0321ENSkillsNetwork26802033-2021-01-01\">Hands-on Lab: Analyzing a real World Data Set</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author(s)\n",
    "\n",
    "<h4> Lakshmi Holla </h4>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Contributors\n",
    "\n",
    "<h4> Rav Ahuja </h4>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change log\n",
    "\n",
    "| Date       | Version | Changed by    | Change Description        |\n",
    "| ---------- | ------- | ------------- | ------------------------- |\n",
    "| 2021-10-12 | 0.4     | Lakshmi Holla | Changed markdown          |\n",
    "| 2021-08-24 | 0.3     | Lakshmi Holla | Added library update      |\n",
    "| 2021-07-09 | 0.2     | Lakshmi Holla | Changes made in magic sql |\n",
    "| 2021-05-20 | 0.1     | Lakshmi Holla | Created Initial Version   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <h3 align=\"center\"> © IBM Corporation 2021. All rights reserved. <h3/>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
